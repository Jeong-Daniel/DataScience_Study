{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36744c6e",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f149336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f848ebdf",
   "metadata": {},
   "source": [
    "### CIFAR10 데이터세트 불러오기\n",
    "transforms.normalize은 특정 평균과 표준편차를 따르는 정규분포를 통해 이미지를 표준화하는 방법이다. CIFAR10은 3채널 컬러 이미지이므로 각 장의 평균과 표준편차를 정한다. 첫번째 0.5,0.5,0.5는 각 채널당 평균을 할당한 것이고 튜플로 입력한다. 두번째는 각 채널의 표준편차다. 평균과 표준편차는 학습전 가지고 있는 이미지로부터 계산하지만 이번에는 임의의 값 0.5를 기입한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b0f3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True) \n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f58fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "# CPU/GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ff377",
   "metadata": {},
   "source": [
    "AlexNet 구축하기\n",
    "본래 AlexNet는 ImageNet 데이터를 위해 만들어졌다. Imagenet은 1000개의 클래스로분류되어 있는 256x256 또는 224x224 크기를 갖는 이미지이다. 따라서 크기가 32x32인 CIFAR10 이미지는 제대로 작동하지 않을 수 있다. 따라서 데이터에 맞게 필터와 크기와 보폭수를 조정해 모델을 구축한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "310dc1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv→ReLU→MaxPool→ Conv→ReLU→MaxPool→Conv→ReLU→ Conv→ReLU→Conv→ReLU→MaxPool→FC1→ReLU→FC2→ReLU→FC3\n",
    "\n",
    "class AlexNet(nn.Module): # 클래스 생성\n",
    "    def __init__(self): # 함수 구조 작성\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential( \n",
    "                        nn.Conv2d(3, 64, 3), nn.ReLU(), #CIFAR110은 RGB컬러 이미지다 따라서 입력 채널의 수가 3이므로 채널 수르 3으로 설정\n",
    "                        nn.MaxPool2d(2, 2),\n",
    "                        nn.Conv2d(64, 192, 3, padding=1), nn.ReLU(),\n",
    "                        nn.MaxPool2d(2, 2),\n",
    "                        nn.Conv2d(192, 384, 3, padding=1), nn.ReLU(),\n",
    "                        nn.Conv2d(384, 256, 3, padding=1), nn.ReLU(),\n",
    "                        nn.Conv2d(256, 256, 1), nn.ReLU(),\n",
    "                        nn.MaxPool2d(2, 2)        \n",
    "                        )\n",
    "        # sequential을 사용하면 순차적으로 행해지는 연산을 한 번에 묶을 수 있다. nn.Sequential의 괄호 안은 작성 순서대로 연산이 수행된다.\n",
    "        self.classifier = nn.Sequential(\n",
    "                        nn.Dropout(0.5),\n",
    "                        nn.Linear(256*3*3, 1024), nn.ReLU(),\n",
    "                        nn.Dropout(0.5),\n",
    "                        nn.Linear(1024, 512), nn.ReLU(),\n",
    "                        nn.Linear(512, 10)\n",
    "                        )    \n",
    "        #Fully-connected layer로 구성된 self.classifer을 정의한다.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 256*3*3)\n",
    "        x = self.classifier(x)    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ec1a7",
   "metadata": {},
   "source": [
    "### 손실 함수 및 최적화 방법 정의하기\n",
    "다중 분류 문제에서는 Cross Entropy Loss를 기본으로 사용한다. 파이토치에서 제공하는 Cross Entropy Loss는 softmax계산까지 포함되어 있으므로 모델의 마지막 출력값에 별도의 softmax를 적용하지 않아도 된다. 그리고 GPU연산을 위해 모델을 불러 올대 .to(device)를 반드시 붙여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc1894bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss는 softmax 계산까지 포함되어 있으므로 모델의 마지막 output node에 별도의 활성화 함수를 사용하지 않아도 된다.\n",
    "alexnet = AlexNet().to(device) # 모델 선언\n",
    "optimizer = optim.Adam(alexnet.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114edcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 1.589\n",
      "[2] loss: 1.172\n",
      "[3] loss: 0.996\n",
      "[4] loss: 0.884\n",
      "[5] loss: 0.801\n",
      "[6] loss: 0.734\n",
      "[7] loss: 0.683\n",
      "[8] loss: 0.635\n"
     ]
    }
   ],
   "source": [
    "# 모델의 학습 과정인 인공 신경망과 동일하다.\n",
    "loss_ = [] # 그래프를 그리기 위한 loss 저장용 리스트 \n",
    "n = len(trainloader) # 배치 개수\n",
    "\n",
    "for epoch in range(50):  # 10번 학습을 진행한다.\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:\n",
    "\n",
    "        inputs, labels = data[0].to(device), data[1].to(device) # 배치 데이터 \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = alexnet(inputs) # 예측값 산출 \n",
    "        loss = criterion(outputs, labels) # 손실함수 계산\n",
    "        loss.backward() # 손실함수 기준으로 역전파 선언\n",
    "        optimizer.step() # 가중치 최적화\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    loss_.append(running_loss / n)    \n",
    "    print('[%d] loss: %.3f' %(epoch + 1, running_loss / len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5507992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 손실 함수 그래프 그리기\n",
    "plt.plot(loss_)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e48a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#파이토치 모델 저장 및 불러오기\n",
    "print(alexnet)\n",
    "PATH = './models/cifar_alexnet.pth' # 모델 저장 경로 \n",
    "torch.save(alexnet.state_dict(), PATH) # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29595d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기는 엄밀히 말하자면 모델의 파라메타를 불러오는 것이다. 따라서 모델의 뼈대를 먼저 선언하고\n",
    "# 모델의 파라메타를 불러와 pretrained model을 만든다.\n",
    "\n",
    "alexnet = AlexNet().to(device) # 모델 선언\n",
    "alexnet.load_state_dict(torch.load(PATH)) # 모델 파라메타 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1c6831",
   "metadata": {},
   "source": [
    "### 모델 정확도 구하기 / 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 데이터를 이용해 정확도를 구해보자.\n",
    "# output은 미니배치의 결과가 산출되기 때문에 for문을 통해서 test 전체의 예측값을 구한다.\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    alexnet.eval()\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = alexnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0) # 개수 누적(총 개수)\n",
    "        correct += (predicted == labels).sum().item() # 누적(맞으면 1, 틀리면 0으로 합산)\n",
    "        \n",
    "print('Test accuracy: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a0945",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "ImageNet 데이터에 맞춰진 ResNet은 기본층에서 7x7 필터를 사용하는 합성곱과 3x3 맥스 풀링을 사용한다. CIFAR10은 이미지 사이즈가 ImageNet 이미지보다 훨씬 작기 때문에 그림과 같이 기본층의 합성곱 필터 사이즈를 3x3으로 줄이고 맥스 풀링을 생략한다. 또한 Resnet18과 ResNet34는 동일한 블록을 사용하기 때문에 층을 조절하여 두 모델을 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e16282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.out_channels))\n",
    "        #학습을 빠르게 할 수 있는 배치 정규화를 층 사이에 적용한다.\n",
    "        #배치 정규화는 각 배치의 평규과 분산을 이용해서 데이터를 정규화하는 방법이다.\n",
    "        if self.stride != 1 or self.in_channels != self.out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                            nn.Conv2d(self.in_channels, self.out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                            nn.BatchNorm2d(self.out_channels))\n",
    "    def forward(self, x):\n",
    "        out = self.conv_block(x)\n",
    "        if self.stride != 1 or self.in_channels != self.out_channels:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        out = F.relu(x + out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.base = nn.Sequential(\n",
    "                        nn.Conv2d(3, 64, kernel_size=3,stride=1, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU())\n",
    "        self.layer1 = self._make_layer(64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(512, num_blocks[3], stride=2)\n",
    "        self.gap = nn.AvgPool2d(4) # 4: 필터 사이즈\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            block = ResidualBlock(self.in_channels, out_channels, stride)\n",
    "            layers.append(block)\n",
    "            self.in_channels = out_channels\n",
    "    \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.base(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def modeltype(model):\n",
    "    if model == 'resnet18':\n",
    "        return ResNet([2, 2, 2, 2])\n",
    "\n",
    "    elif model == 'resnet34':\n",
    "        return ResNet([3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc2249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = modeltype('resnet18').to(device)\n",
    "print(resnet)\n",
    "PATH = './models/cifar_resnet.pth' # 모델 저장 경로 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938db668",
   "metadata": {},
   "source": [
    "파이토치에서는 손쉽게 이용할 수 있는 다양한 신경망을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c980e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "alexnet = models.alexnet().to(divice)\n",
    "alexnet.classifier[6] = nn.Linear(4096,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18().to(device)\n",
    "vgg16 = models.vgg16().to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
