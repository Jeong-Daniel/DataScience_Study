{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d0bee7",
   "metadata": {},
   "source": [
    "### 데이터 불러오기\n",
    "메모리같은 제한된 자원으로 인해 모든 데이터를 메모리에 올려서 학습하기는 힘들기 때문에 일반적으로 배치 형태의 묶음으로 데이터를 나누어 모델 학습에 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "152b40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # 파이토치 기본 라이브러리 \n",
    "import torchvision # 이미지 관련 된 파이토치 라이브러리\n",
    "import torchvision.transforms as tr # 이미지 전처리 기능들을 제공하는 라이브러리\n",
    "from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n",
    "import numpy as np # 넘파이 기본 라이브러리\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6e63c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr.Compose 내에 원하는 전처리를 차례대로 넣어주면 된다.\n",
    "\n",
    "transf = tr.Compose([tr.Resize(16),tr.ToTensor()]) # 16x16으로 이미지 크기 변환 후 텐서 타입으로 변환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0cf0f4",
   "metadata": {},
   "source": [
    "Transforms on PIL Image  \n",
    "Pad, Grayscale, RandomCrop, Normalize ..  \n",
    "Transforms on torch.*Tensor - tensor image  \n",
    "torchvision.transforms.ToPILImage(mode=None)...  \n",
    "\n",
    "torchvision.datasets에서 제공하는 CIFAR10 데이터를 불러온다.  \n",
    "root에는 다운로드 받을 경로를 입력한다.  \n",
    "train=Ture이면 학습 데이터를 불러오고 train=False이면 테스트 데이터를 불러온다.  \n",
    "미리 선언한 전처리를 사용하기 위해 transform=transf을 입력한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae964ed7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d9caa",
   "metadata": {},
   "source": [
    "일반적으로 데이터셋은 이미지와 라벨이 동시에 들어있는 튜플(tuple) 형태다. (이미지, 라벨)  \n",
    "trainset[0]은 학습 데이터의 첫 번째 데이터로 이미지 한 장과 라벨 숫자 하나가 저장되어 있다.  \n",
    "즉, trainset[0][0]은 이미지이며 trainset[0][1]은 라벨이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad5191c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(trainset[0][0].size()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f8984",
   "metadata": {},
   "source": [
    "현재 이미지 사이즈는 3x16x16이다. 여기서 3은 채널 수를 말하고 16x16은 이미지의 너비와 높이를 의미한다.  \n",
    "일반적인 컬러 사진은 RGB 이미지이기 때문에 채널이 3개 이고 (너비)x(높이)x(채널 수)로 크기가 표현된다.  \n",
    "하지만 파이토치에서는 이미지 한 장이 (채널 수)x(너비)x(높이)으로 표현되니 유의하도록 한다.\n",
    "\n",
    "DataLoader는 데이터를 미니 배치 형태로 만들어 준다.  \n",
    "따라서 배치 사이즈 및 셔플 여부 등을 선택할 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66dcf957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=50, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=50, shuffle=False)\n",
    "\n",
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d19211",
   "metadata": {},
   "source": [
    "CIFAR10의 학습 이미지는 50,000장이고 배치 사이즈가 50장이므로 1,000은 배치의 개수가 된다.  \n",
    "즉 trainloader가 잘 만들어졌다는 것을 단편적으로 알 수 있다.  \n",
    "iter, next를 이용해 일부 데이터를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c4fcffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "images, labels = iter(trainloader).next()\n",
    "print(images.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8823d08",
   "metadata": {},
   "source": [
    "일반적으로 학습 데이터는 4차원 형태로 모델에서 사용된다.  \n",
    "(배치 크기)x(채널 수)x(너비)x(높이)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf8f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "oneshot = images[1].permute(1,2,0).numpy()\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(oneshot)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "#컴퓨터에 따라서 이미지 호출하면 커널이 다운될 수 있음\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9650ba34",
   "metadata": {},
   "source": [
    "### 이미지를 같은 클래스(라벨)별로 폴더를 정리한 경우\n",
    "데이터가 같은 클래스 별로 미리 폴더를 정리 된 경우, ImageFolder의 1줄 선언으로 개인 데이터를 사용할 수 있다.  \n",
    "별도의 라벨링이 필요 없으며 폴더 별로 자동으로 라벨링을 한다.  \n",
    "예를 들어 class 폴더에 tiger, lion 폴더(./class/tiger와 ./class/lion)를 미리 만든다.  \n",
    "다음으로 ImageFolder에 상위 폴더 ./class를 입력하면 이미지와 라벨이 정리 되어 데이터를 불러온다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a9fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "transf = tr.Compose([tr.Resize(128),tr.ToTensor()]) # 128x128 이미지 크기 변환 후 텐서로 만든다.\n",
    "trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf) # 커스텀 데이터 불러온다.\n",
    "trainloader = DataLoader(trainset, batch_size=2, shuffle=False) # 데이터를 미니 배치 형태로 만들어 준다.\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.size(),labels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851bfba",
   "metadata": {},
   "source": [
    "### 정리되지 않은 커스텀 데이터 불러오기\n",
    "ImageFolder를 이용하면 매우 간단하게 이미지 데이터를 사용할 수 있지만 여러가지 이유로 사용이 불가능한 경우가 있다.  \n",
    "1. 라벨 별로 폴더 정리가 되어 있으면 좋겠지만 그렇지 않은 경우가 많다.\n",
    "2. 정리를 하고 싶지만 다른 작업들과 공유된 데이터인 경우 폴더를 함부로 정리할 수 없다.\n",
    "3. 이미지 데이터라도 이미지가 아닌 텍스트, 리스트 ,배열 등의 다른 형태로 저장되어 있는 경우도 있다.\n",
    "\n",
    "아래는 가장 기본적인 형태이다\n",
    "\n",
    "from torch.utils.data import Dataset  \n",
    "\n",
    "class MyDataset(Dataset):  <- Dataset을 상속받아 DataLoader에서 배치 단위로 불러 올 수 있게 해준다.\n",
    "    \n",
    "    def __init__(self):  <- 데이터 세팅에 필요한 것들을 정의\n",
    "    \n",
    "    def __getitem__(self, index):  <- Dataloader를 통해 샘플이 요청되면 __getitem__(self,index)은 인덱스에 해당하는 샘플을 찾아 준다\n",
    "    \n",
    "    def __len__(self):  <- 은 크기를 반환한다.\n",
    "\n",
    "이 양식을 통으로 가지고 다니자!!\n",
    "\n",
    "### 커스텀 데이터 세트 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b30dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32x32 컬러 이미지와 라벨이 각각 100장이 있다고 가정하다.\n",
    "\n",
    "train_images = np.random.randint(256,size=(100,32,32,3))/255 # (이미지 수)x(너비)x(높이)x(채널 수)\n",
    "train_labels = np.random.randint(2,size=(100,1)) # 라벨 수\n",
    "\n",
    "class TensorData(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data) # 이미지 데이터를 FloatTensor로 변형\n",
    "        self.x_data = self.x_data.permute(0,3,1,2) # (이미지 수)x(너비)x(높이)x(채널 수) -> (배치 크기)x(채널 수)x(너비)x(높이)\n",
    "        self.y_data = torch.LongTensor(y_data) # 라벨 데이터를 LongTensor로 변형\n",
    "        self.len = self.y_data.shape[0] # 클래스 내의 들어 온 데이터 개수 \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index] # 뽑아 낼 데이터를 적어준다.\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len # 클래스 내의 들어 온 데이터 개수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bffad873",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorData(train_images,train_labels) # 텐서 데이터 불러오기 \n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True) # 미니 배치 형태로 데이터 갖추기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134c973",
   "metadata": {},
   "source": [
    "### 커스텀 데이터와 커스텀 전처리 사용하기\n",
    "파이토치는 전처리 함수들을 제공하여 매우 편리하게 사용할 수 있다. 하지만 이미지의 경우 PIL-image 타입이거나 Tensor타입일 때 사용이 가능하다. 또한 제공하지 않는 기능에 대해서는 직접 구현이 필요하다. 이번 예시에서는 두개의 클래스를 직접 정의하고 사용한다  \n",
    "먼저 텐서변환 전처리 클래스를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40762e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as tr # 이미지 전처리 기능들을 제공하는 라이브러리\n",
    "from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n",
    "import numpy as np # 넘파이 기본 라이브러리\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85fb20af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 텐서 변환\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        inputs = torch.FloatTensor(inputs) # 텐서로 변환\n",
    "        inputs = inputs.permute(2,0,1) # 크기 변환\n",
    "        return inputs, torch.LongTensor(labels) # 텐서로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6f8ec",
   "metadata": {},
   "source": [
    "CutOut은 이미지 내부에 무작위로 사각형 영역을 선택하여 0으로 만드는 데이터 증식 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0401ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CutOut    \n",
    "class CutOut:\n",
    "    \n",
    "    def __init__(self, ratio=.5):\n",
    "        self.ratio = int(1/ratio)\n",
    "        # __init__함수를 사용하여 ratio를 받는다. 기본 ratio는 0.5로 세팅하면 불러온 이미지에 대해 50% 확률로 CutOut을 발현\n",
    "           \n",
    "    def __call__(self, sample): # 샘플을 받는다.\n",
    "        inputs, labels = sample\n",
    "        active = int(np.random.randint(0, self.ratio, 1))\n",
    "        \n",
    "        if active == 0:\n",
    "            _, w, h = inputs.size()\n",
    "            min_len = min(w, h)\n",
    "            box_size = int(min_len//4)\n",
    "            idx = int(np.random.randint(0, min_len-box_size, 1))\n",
    "            inputs[:,idx:idx+box_size,idx:idx+box_size] = 0\n",
    "        \n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef620b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 사용한 양식을 그대로 사용하되 전처리 작업을 할 수 있도록 transform을 추가한다. \n",
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data, transform=None):\n",
    "        \n",
    "        self.x_data = x_data # 넘파이 배열이 들어온다.\n",
    "        self.y_data = y_data # 넘파이 배열이 들어온다.\n",
    "        self.transform = transform\n",
    "        self.len = len(y_data)\n",
    "        self.tensor = ToTensor()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample) #self.transform이 None이 아니라면 전처리를 작업한다.\n",
    "        else:\n",
    "            sample = self.tensor(sample)\n",
    "        \n",
    "        return sample \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab07c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trans = tr.Compose([ToTensor(),LinearTensor(2,5)]) # 텐서 변환 후 선형식 2x+5 연산\n",
    "trans = tr.Compose([ToTensor(),CutOut()]) \n",
    "dataset1 = MyDataset(train_images,train_labels, transform=trans)\n",
    "train_loader1 = DataLoader(dataset1, batch_size=10, shuffle=True)\n",
    "\n",
    "# ToTensor()와 tr.ToTensor()의 차이\n",
    "# 앞 서 사용한 tr.ToTensor()는 import torchvision.transforms as tr를 이용한 파이토치 메소드를 이용한 것이고\n",
    "# ToTensor()는 위에서 정의 된 메소드를 사용한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97e38c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "images1, labels1 = iter(train_loader1).next()\n",
    "print(images1.size()) # 배치 및 이미지 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa96eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "def imshow(img):\n",
    "    plt.figure(figsize=(10,100))\n",
    "    plt.imshow(img.permute(1,2,0).numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a8699ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imshow(torchvision.utils.make_grid(images1,nrow=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cce295",
   "metadata": {},
   "source": [
    "### 커스텀 데이터와 파이토치 제공 전처리 사용하기\n",
    "텐서 변환과 같은 전처리는 파이토치에서 제공하는 전처리를 사용하면 편리하다. 하지만 앞서 언급했듯이 ㅏㅍ이토치에서 제공되는 많은 전처리는 PILImage 타입일 경우 사용할 수 있다. 따라서 기능은 있는데 데이터 타입이 다른 경우는 PILImage 타입으로 변환하여 제공된 전처리를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a18e006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.transforms에서 제공하는 전처리 기술을 사용한다.\n",
    "# torchvision.transforms은 입력 이미지가 일반적으로 PILImage 타입이나 텐서일 경우에 동작한다.\n",
    "# 현재 데이터는 넘파이 배열이다. 따라서 텐서 변환 후 tr.ToPILImage()을 이용하여 PILImage 타입으로 만들어 준다.\n",
    "# __call__을 이용한 기본 구조는 동일하다.\n",
    "\n",
    "class MyTransform:\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        inputs = torch.FloatTensor(inputs)\n",
    "        inputs = inputs.permute(2,0,1)\n",
    "        labels = torch.FloatTensor(labels)\n",
    "\n",
    "        transf = tr.Compose([tr.ToPILImage(), tr.Resize(128), tr.ToTensor()])\n",
    "        final_output = transf(inputs)      \n",
    "        \n",
    "        return final_output, labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2475491",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = MyDataset(train_images,train_labels, transform=MyTransform())\n",
    "train_loader2 = DataLoader(dataset2, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0463c4e9",
   "metadata": {},
   "source": [
    "### 커스텀 데이터와 파이토치 제공 전처리 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c473f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutOut:\n",
    "    \n",
    "    def __init__(self, ratio=.5):\n",
    "        self.ratio = int(1/ratio)\n",
    "           \n",
    "    def __call__(self, inputs):\n",
    "\n",
    "        active = int(np.random.randint(0, self.ratio, 1))\n",
    "        \n",
    "        if active == 0:\n",
    "            _, w, h = inputs.size()\n",
    "            min_len = min(w, h)\n",
    "            box_size = int(min_len//4)\n",
    "            idx = int(np.random.randint(0, min_len-box_size, 1))\n",
    "            inputs[:,idx:idx+box_size,idx:idx+box_size] = 0\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=10, shuffle=True)\n",
    "images, labels = iter(trainloader).next()\n",
    "imshow(torchvision.utils.make_grid(images,nrow=10))\n",
    "print(images.size()) # 배치 및 이미지 크기 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
